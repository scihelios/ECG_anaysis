import numpy as np
import os
import json
from sklearn.model_selection import train_test_split

# LMS Filter Class
import torch
import torch.nn as nn
import torch.optim as optim

class MLPModel(nn.Module):
    def __init__(self):
        super(MLPModel, self).__init__()
        self.fc1 = nn.Linear(1500, 200)  # Adjust the input size to match the window size
        self.fc2 = nn.Linear(200, 200)
        self.fc3 = nn.Linear(200, 100)
        self.fc4 = nn.Linear(100, 100)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.relu(self.fc3(x))
        return self.fc4(x)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)
def load_data(folder_path, window_size , predection_size):
    all_sequences = []
    all_targets = []
    k=0
    for file_name in os.listdir(folder_path):
        if  file_name.endswith('.json') and k<500:
            print(file_name)
            k+=1
            with open(os.path.join(folder_path, file_name), 'r') as file:
                data = json.load(file)
                long_sequence = data["signal"]
                print(len(long_sequence))
                for i in range(0,len(long_sequence) - window_size - predection_size,100):
                    window = long_sequence[i:i + window_size]
                    next_point = long_sequence[i + window_size :  predection_size+i + window_size]
                    all_sequences.append(window)
                    all_targets.append(next_point)
    print(len(all_sequences))
    return np.array(all_sequences), np.array(all_targets)

window_size = 1500
predection_size = 100 
inputs, targets = load_data('C:/Users/ahmed mansour/Desktop/scolarite X/2A/Psc/ECG_anaysis/excess_code/new_data', window_size , predection_size)
inputs_tensor = torch.tensor(inputs, dtype=torch.float32)
targets_tensor = torch.tensor(targets, dtype=torch.float32)

# Split the data into training and validation sets
train_sequences, val_sequences, train_labels, val_labels = train_test_split(
    inputs_tensor, targets_tensor, test_size=0.25, random_state=42)

# Initialize the model, loss function, and optimizer
model = MLPModel().to(device)  # Move model to GPU
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.002)

# Training loop
num_epochs = 30  # Adjust as necessary
from torch.utils.data import DataLoader, TensorDataset

# Create TensorDataset and DataLoader for batch processing
train_dataset = TensorDataset(train_sequences, train_labels)
val_dataset = TensorDataset(val_sequences, val_labels)

batch_size = 4096  # You can adjust this based on your memory capacity
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

# Training loop
for epoch in range(num_epochs):
    model.train()
    total_loss = 0
    for batch in train_loader:
        inputs, targets = batch[0].to(device), batch[1].to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch + 1}/{num_epochs}, Training Loss: {total_loss / len(train_loader)}")

    # Validation step
    model.eval()
    val_losses = []
    with torch.no_grad():
        for batch in val_loader:
            inputs, targets = batch[0].to(device), batch[1].to(device)  # Move data to GPU
            outputs = model(inputs)
            val_loss = criterion(outputs, targets)
            val_losses.append(val_loss.item())
            
    avg_val_loss = np.mean(val_losses)
    print(f"Validation Loss: {avg_val_loss:.4f}")

def iterative_forecast(initial_data, model, steps):
    """
    Predict future points iteratively using the MLP model.

    :param initial_data: List of initial 1600 points.
    :param model: Trained MLP model.
    :param steps: Number of future points to predict.
    :return: List containing the initial data followed by the predicted points.
    """
    data = initial_data.copy()
    model.eval()  # Set the model to evaluation mode

    with torch.no_grad():
        for _ in range(steps):
            # Use the latest 1600 points for prediction
            current_input = torch.tensor(data[-window_size:], dtype=torch.float32)
            current_input = current_input.unsqueeze(0)  # Add batch dimension
            current_input = current_input.to(device) 
            prediction = model(current_input)
            next_point = prediction.tolist()[0]  # Convert tensor to scalar
            data = data + next_point

    return data


import matplotlib.pyplot as plt
# Assuming `lms_filter` is your trained LMS filter
# And `initial_points` is your list of initial 400 points
initial_points = [ 0.6137957911145752, 0.6145752143413874, 0.6149649259547935, 0.6118472330475448, 0.6208106001558846, 0.6321122369446609, 0.6336710833982853, 0.6336710833982853, 0.6344505066250974, 0.642634450506625, 0.6449727201870615, 0.6457521434138738, 0.6504286827747466, 0.6496492595479345, 0.6477007014809041, 0.6492595479345284, 0.6434138737334373, 0.6356196414653157, 0.6328916601714731, 0.6293842556508183, 0.6325019485580671, 0.6293842556508183, 0.6243180046765393, 0.6208106001558846, 0.6153546375681995, 0.6157443491816056, 0.6122369446609509, 0.6114575214341388, 0.6169134840218239, 0.6200311769290725, 0.622369446609509, 0.6262665627435697, 0.6309431021044427, 0.6305533904910366, 0.6278254091971941, 0.6247077162899455, 0.6313328137178488, 0.6387373343725643, 0.6309431021044427, 0.6286048324240062, 0.6282151208106002, 0.6289945440374123, 0.6286048324240062, 0.6250974279033515, 0.6250974279033515, 0.6215900233826968, 0.6204208885424786, 0.6141855027279813, 0.6052221356196414, 0.6106780982073265, 0.6063912704598597, 0.5985970381917382, 0.5974279033515199, 0.5900233826968043, 0.5849571317225253, 0.5728760717069369, 0.5709275136399065, 0.5724863600935308, 0.5681995323460639, 0.5693686671862821, 0.5576773187840998, 0.5506625097427903, 0.5561184723304754, 0.5572876071706937, 0.553780202650039, 0.5522213561964147, 0.5541699142634451, 0.5494933749025721, 0.5471551052221356, 0.54871395167576, 0.5436477007014809, 0.538971161340608, 0.5311769290724864, 0.5249415432579891, 0.534294621979735, 0.5366328916601715, 0.538971161340608, 0.5475448168355417, 0.5452065471551052, 0.5401402961808262, 0.538971161340608, 0.5444271239282931, 0.5452065471551052, 0.5432579890880749, 0.538971161340608, 0.5358534684333593, 0.5374123148869836, 0.5378020265003897, 0.5459859703819174, 0.5502727981293842, 0.5397505845674201, 0.5366328916601715, 0.538971161340608, 0.5401402961808262, 0.5452065471551052, 0.5409197194076384, 0.5354637568199533, 0.538971161340608, 0.5350740452065471, 0.5300077942322681, 0.534684333593141, 0.5378020265003897, 0.534684333593141, 0.5354637568199533, 0.5362431800467654, 0.5319563522992985, 0.5362431800467654, 0.538971161340608, 0.5354637568199533, 0.5319563522992985, 0.5319563522992985, 0.5311769290724864, 0.5331254871395168, 0.5409197194076384, 0.5420888542478566, 0.5385814497272019, 0.5362431800467654, 0.5413094310210445, 0.5385814497272019, 0.5370226032735775, 0.5331254871395168, 0.5265003897116134, 0.5210444271239283, 0.5128604832424006, 0.5124707716289946, 0.5105222135619641, 0.5132501948558067, 0.5124707716289946, 0.5077942322681216, 0.5074045206547155, 0.5066250974279034, 0.5007794232268121, 0.495323460639127, 0.49727201870615745, 0.4929851909586906, 0.4898674980514419, 0.485190958690569, 0.480514419329696, 0.48012470771628996, 0.48558067030397506, 0.4984411535463757, 0.49961028838659394, 0.5011691348402182, 0.4922057677318784, 0.49883086515978176, 0.5109119251753702, 0.5132501948558067, 0.544037412314887, 0.5584567420109119, 0.5720966484801248, 0.6044427123928293, 0.627435697583788, 0.6515978176149649, 0.6773187840997662, 0.696024941543258, 0.715900233826968, 0.7381137957911146, 0.7552611067809821, 0.7669524551831645, 0.7852689010132502, 0.8094310210444271, 0.8355416991426344, 0.8667186282151208, 0.88269680436477, 0.8784099766173032, 0.8445050662509743, 0.8059236165237724, 0.7860483242400623, 0.7704598597038191, 0.779423226812159, 0.7930631332813718, 0.7965705378020265, 0.8172252533125487, 0.8343725643024162, 0.843335931410756, 0.8363211223694466, 0.8051441932969603, 0.779033515198753, 0.7517537022603273, 0.7131722525331254, 0.6660171473109898, 0.6215900233826968, 0.588074824629774, 0.5627435697583788, 0.5362431800467654, 0.5120810600155885, 0.5003897116134061, 0.5011691348402182, 0.509742790335152, 0.5187061574434918, 0.5253312548713952, 0.534294621979735, 0.5416991426344505, 0.54871395167576, 0.5565081839438816, 0.5568978955572876, 0.5549493374902572, 0.5549493374902572, 0.553780202650039, 0.5483242400623538, 0.5459859703819174, 0.5483242400623538, 0.5502727981293842, 0.5455962587685113, 0.5413094310210445, 0.5424785658612626, 0.5459859703819174, 0.544037412314887, 0.5401402961808262, 0.5397505845674201, 0.5385814497272019, 0.5358534684333593, 0.5362431800467654, 0.5335151987529229, 0.5292283710054559, 0.538971161340608, 0.5436477007014809, 0.5436477007014809, 0.5378020265003897, 0.5323460639127046, 0.5424785658612626, 0.5413094310210445, 0.5413094310210445, 0.5483242400623538, 0.5479345284489477, 0.5475448168355417, 0.5448168355416991, 0.5452065471551052, 0.5452065471551052, 0.534294621979735, 0.5292283710054559, 0.5339049103663289, 0.5370226032735775, 0.5416991426344505, 0.5428682774746687, 0.5436477007014809, 0.5428682774746687, 0.5424785658612626, 0.5405300077942322, 0.5385814497272019, 0.5424785658612626, 0.544037412314887, 0.5428682774746687, 0.5358534684333593, 0.5416991426344505, 0.5498830865159782, 0.544037412314887, 0.5416991426344505, 0.5444271239282931, 0.5416991426344505, 0.5409197194076384, 0.5467653936087296, 0.5494933749025721, 0.5518316445830086, 0.5424785658612626, 0.5385814497272019, 0.5510522213561965, 0.5498830865159782, 0.5452065471551052, 0.5494933749025721, 0.5483242400623538, 0.5424785658612626, 0.5401402961808262, 0.5413094310210445, 0.5436477007014809, 0.5444271239282931, 0.5424785658612626, 0.5467653936087296, 0.5502727981293842, 0.5459859703819174, 0.5436477007014809, 0.5448168355416991, 0.5455962587685113, 0.5420888542478566, 0.54871395167576, 0.5448168355416991, 0.5366328916601715, 0.5428682774746687, 0.5479345284489477, 0.5526110678098207, 0.5494933749025721, 0.5432579890880749, 0.5475448168355417, 0.549103663289166, 0.5467653936087296, 0.5502727981293842, 0.5467653936087296, 0.5459859703819174, 0.5448168355416991, 0.5436477007014809, 0.5498830865159782, 0.549103663289166, 0.5459859703819174, 0.5448168355416991, 0.5432579890880749, 0.5405300077942322, 0.5397505845674201, 0.5378020265003897, 0.538971161340608, 0.5455962587685113, 0.5448168355416991, 0.5428682774746687, 0.5409197194076384, 0.544037412314887, 0.54871395167576, 0.54871395167576, 0.5526110678098207, 0.5596258768511302, 0.5568978955572876, 0.5483242400623538, 0.5510522213561965, 0.5518316445830086, 0.544037412314887, 0.5432579890880749, 0.5432579890880749, 0.5424785658612626, 0.5428682774746687, 0.5467653936087296, 0.5475448168355417, 0.5432579890880749, 0.5459859703819174, 0.5448168355416991, 0.5428682774746687, 0.544037412314887, 0.5479345284489477, 0.5526110678098207, 0.5479345284489477, 0.5444271239282931, 0.5467653936087296, 0.5522213561964147, 0.5565081839438816, 0.5545596258768511, 0.5530007794232268, 0.5475448168355417, 0.5428682774746687, 0.5459859703819174, 0.5533904910366328, 0.5514419329696025, 0.549103663289166, 0.549103663289166, 0.5385814497272019, 0.5385814497272019, 0.5413094310210445, 0.539360872954014, 0.5424785658612626, 0.5452065471551052, 0.5448168355416991, 0.5405300077942322, 0.5397505845674201, 0.5455962587685113, 0.5526110678098207, 0.5510522213561965, 0.5502727981293842, 0.5506625097427903, 0.549103663289166, 0.5428682774746687, 0.534294621979735, 0.5385814497272019, 0.5381917381137958, 0.5409197194076384, 0.5413094310210445, 0.539360872954014, 0.5432579890880749, 0.5335151987529229, 0.5358534684333593, 0.5381917381137958, 0.5307872174590803, 0.5311769290724864, 0.5311769290724864, 0.5370226032735775, 0.5405300077942322, 0.5366328916601715, 0.5374123148869836, 0.534684333593141, 0.5300077942322681, 0.5276695245518317, 0.5300077942322681, 0.5315666406858924, 0.5303975058456742, 0.5405300077942322, 0.5327357755261107, 0.5218238503507404, 0.5292283710054559, 0.5366328916601715, 0.5350740452065471, 0.5300077942322681, 0.5261106780982073, 0.5241621200311769, 0.5284489477786438, 0.5307872174590803, 0.5362431800467654, 0.5354637568199533, 0.534684333593141, 0.5335151987529229, 0.5292283710054559, 0.5303975058456742, 0.5257209664848013, 0.5284489477786438, 0.5358534684333593, 0.5292283710054559, 0.5335151987529229, 0.5276695245518317, 0.5190958690568979, 0.5249415432579891, 0.5249415432579891, 0.5233826968043648, 0.5257209664848013, 0.5280592361652378, 0.5249415432579891, 0.5315666406858924, 0.5319563522992985, 0.529618082618862, 0.5319563522992985, 0.5366328916601715, 0.5362431800467654, 0.5303975058456742, 0.529618082618862, 0.5339049103663289, 0.5350740452065471, 0.5315666406858924, 0.5358534684333593, 0.5335151987529229, 0.5303975058456742, 0.5335151987529229, 0.5307872174590803, 0.5307872174590803, 0.5378020265003897, 0.5385814497272019, 0.5416991426344505, 0.5436477007014809, 0.5420888542478566, 0.5378020265003897, 0.5350740452065471, 0.538971161340608, 0.5315666406858924, 0.534294621979735, 0.5413094310210445, 0.5323460639127046, 0.5374123148869836, 0.5533904910366328, 0.5518316445830086, 0.549103663289166, 0.5475448168355417, 0.538971161340608, 0.5518316445830086, 0.558846453624318, 0.5611847233047544, 0.563912704598597, 0.54871395167576, 0.5494933749025721, 0.5506625097427903, 0.5471551052221356, 0.5428682774746687, 0.5448168355416991, 0.5514419329696025, 0.5522213561964147, 0.5475448168355417, 0.549103663289166, 0.5600155884645363, 0.5549493374902572, 0.5483242400623538, 0.553780202650039, 0.5631332813717849, 0.5592361652377241, 0.5522213561964147, 0.5545596258768511, 0.5479345284489477, 0.5409197194076384, 0.5471551052221356, 0.5510522213561965, 0.5502727981293842, 0.5494933749025721, 0.5514419329696025, 0.5483242400623538, 0.5436477007014809, 0.5467653936087296, 0.5518316445830086, 0.5553390491036633, 0.5506625097427903, 0.5514419329696025, 0.5530007794232268, 0.5545596258768511, 0.5592361652377241, 0.5545596258768511, 0.5580670303975058, 0.5545596258768511, 0.5467653936087296, 0.5561184723304754, 0.5600155884645363, 0.5557287607170693, 0.54871395167576, 0.5483242400623538, 0.5553390491036633, 0.558846453624318, 0.5604053000779423, 0.5623538581449727, 0.5576773187840998, 0.5533904910366328, 0.5604053000779423, 0.5646921278254092, 0.5627435697583788, 0.5553390491036633, 0.5498830865159782, 0.5526110678098207, 0.5522213561964147, 0.5541699142634451, 0.5607950116913484, 0.5549493374902572, 0.5483242400623538, 0.5592361652377241, 0.5635229929851909, 0.558846453624318, 0.5549493374902572, 0.5557287607170693, 0.5553390491036633, 0.5549493374902572, 0.5592361652377241, 0.5514419329696025, 0.5526110678098207, 0.5572876071706937, 0.5541699142634451, 0.5549493374902572, 0.5572876071706937, 0.5526110678098207, 0.5580670303975058, 0.5631332813717849, 0.5568978955572876, 0.5584567420109119, 0.5541699142634451, 0.5607950116913484, 0.5611847233047544, 0.5514419329696025, 0.5541699142634451, 0.5530007794232268, 0.5494933749025721, 0.5510522213561965, 0.5561184723304754, 0.5576773187840998, 0.5549493374902572, 0.5494933749025721, 0.5459859703819174, 0.5483242400623538, 0.5506625097427903, 0.5545596258768511, 0.5530007794232268, 0.549103663289166, 0.5530007794232268, 0.5572876071706937, 0.5522213561964147, 0.5494933749025721, 0.5549493374902572, 0.5541699142634451, 0.5643024162120032, 0.5631332813717849, 0.5506625097427903, 0.5561184723304754, 0.5611847233047544, 0.558846453624318, 0.5502727981293842, 0.5533904910366328, 0.5615744349181606, 0.5576773187840998, 0.5502727981293842, 0.5448168355416991, 0.5416991426344505, 0.5381917381137958, 0.5420888542478566, 0.5494933749025721, 0.5494933749025721, 0.5479345284489477, 0.549103663289166, 0.5479345284489477, 0.5432579890880749, 0.5483242400623538, 0.5514419329696025, 0.5533904910366328, 0.5568978955572876, 0.5545596258768511, 0.5510522213561965, 0.5471551052221356, 0.5514419329696025, 0.5498830865159782, 0.5459859703819174, 0.5455962587685113, 0.5420888542478566, 0.5483242400623538, 0.5514419329696025, 0.5506625097427903, 0.5494933749025721, 0.544037412314887, 0.5483242400623538, 0.5483242400623538, 0.5494933749025721, 0.5522213561964147, 0.5518316445830086, 0.5448168355416991, 0.5358534684333593, 0.5455962587685113, 0.5483242400623538, 0.544037412314887, 0.5463756819953235, 0.5467653936087296, 0.549103663289166, 0.5471551052221356, 0.5510522213561965, 0.5498830865159782, 0.5467653936087296, 0.5522213561964147, 0.54871395167576, 0.5479345284489477, 0.5463756819953235, 0.5455962587685113, 0.5424785658612626, 0.5471551052221356, 0.549103663289166, 0.5452065471551052, 0.5444271239282931, 0.5444271239282931, 0.5455962587685113, 0.5436477007014809, 0.544037412314887, 0.5436477007014809, 0.544037412314887, 0.5413094310210445, 0.5494933749025721, 0.549103663289166, 0.54871395167576, 0.5549493374902572, 0.5428682774746687, 0.5378020265003897, 0.5448168355416991, 0.5467653936087296, 0.5479345284489477, 0.5479345284489477, 0.5428682774746687, 0.54871395167576, 0.5483242400623538, 0.5413094310210445, 0.5541699142634451, 0.5541699142634451, 0.5397505845674201, 0.5459859703819174, 0.5545596258768511, 0.5506625097427903, 0.5467653936087296, 0.5502727981293842, 0.54871395167576, 0.5463756819953235, 0.5545596258768511, 0.5553390491036633, 0.549103663289166, 0.549103663289166, 0.5459859703819174, 0.5452065471551052, 0.549103663289166, 0.5545596258768511, 0.5545596258768511, 0.5432579890880749, 0.5467653936087296, 0.54871395167576, 0.5424785658612626, 0.5475448168355417, 0.5483242400623538, 0.5494933749025721, 0.5436477007014809, 0.5385814497272019, 0.539360872954014, 0.5424785658612626, 0.5518316445830086, 0.5381917381137958, 0.539360872954014, 0.5498830865159782, 0.5448168355416991, 0.5530007794232268, 0.54871395167576, 0.549103663289166, 0.553780202650039, 0.5498830865159782, 0.5506625097427903, 0.5510522213561965, 0.553780202650039, 0.5533904910366328, 0.5506625097427903, 0.5498830865159782, 0.5506625097427903, 0.5533904910366328, 0.5510522213561965, 0.5444271239282931, 0.5463756819953235, 0.5494933749025721, 0.5475448168355417, 0.5448168355416991, 0.549103663289166, 0.5518316445830086, 0.5479345284489477, 0.5471551052221356, 0.5471551052221356, 0.5483242400623538, 0.5506625097427903, 0.5475448168355417, 0.5405300077942322, 0.544037412314887, 0.5448168355416991, 0.5436477007014809, 0.5471551052221356, 0.5448168355416991, 0.5483242400623538, 0.5483242400623538, 0.5424785658612626, 0.5452065471551052, 0.5514419329696025, 0.5514419329696025, 0.5561184723304754, 0.5549493374902572, 0.5498830865159782, 0.5467653936087296, 0.54871395167576, 0.5522213561964147, 0.5471551052221356, 0.5526110678098207, 0.5514419329696025, 0.54871395167576, 0.5479345284489477, 0.549103663289166, 0.5545596258768511, 0.5483242400623538, 0.5424785658612626, 0.5459859703819174, 0.5467653936087296, 0.5397505845674201, 0.5479345284489477, 0.549103663289166, 0.5479345284489477, 0.5494933749025721, 0.5475448168355417, 0.549103663289166, 0.5526110678098207, 0.553780202650039, 0.5475448168355417, 0.5549493374902572, 0.5557287607170693, 0.5436477007014809, 0.549103663289166, 0.5584567420109119, 0.5494933749025721, 0.5444271239282931, 0.5459859703819174, 0.549103663289166, 0.5533904910366328, 0.5444271239282931, 0.5381917381137958, 0.5432579890880749, 0.5459859703819174, 0.5424785658612626, 0.5467653936087296, 0.5561184723304754, 0.5518316445830086, 0.5541699142634451, 0.553780202650039, 0.5455962587685113, 0.5494933749025721, 0.5494933749025721, 0.5483242400623538, 0.5502727981293842, 0.5533904910366328, 0.553780202650039, 0.5502727981293842, 0.5553390491036633, 0.5530007794232268, 0.558846453624318, 0.5568978955572876, 0.5452065471551052, 0.5494933749025721, 0.5463756819953235, 0.5557287607170693, 0.5596258768511302, 0.553780202650039, 0.5572876071706937, 0.5623538581449727, 0.5584567420109119, 0.5510522213561965, 0.5494933749025721, 0.5494933749025721, 0.5526110678098207, 0.5502727981293842, 0.5506625097427903, 0.544037412314887, 0.5498830865159782, 0.5549493374902572, 0.5455962587685113, 0.5459859703819174, 0.5455962587685113, 0.5565081839438816, 0.5580670303975058, 0.5463756819953235, 0.5459859703819174, 0.5471551052221356, 0.5405300077942322, 0.5405300077942322, 0.54871395167576, 0.5475448168355417, 0.5483242400623538, 0.5545596258768511, 0.5530007794232268, 0.5498830865159782, 0.5510522213561965, 0.5553390491036633, 0.5518316445830086, 0.5494933749025721, 0.5471551052221356, 0.5413094310210445, 0.5483242400623538, 0.5522213561964147, 0.5526110678098207, 0.553780202650039, 0.5459859703819174, 0.5455962587685113, 0.5526110678098207, 0.5526110678098207, 0.5471551052221356, 0.5455962587685113, 0.5494933749025721, 0.549103663289166, 0.549103663289166, 0.5526110678098207, 0.5533904910366328, 0.5568978955572876, 0.5545596258768511, 0.5494933749025721, 0.5459859703819174, 0.5397505845674201, 0.5424785658612626, 0.5467653936087296, 0.5530007794232268, 0.54871395167576, 0.5459859703819174, 0.5533904910366328, 0.5506625097427903, 0.5510522213561965, 0.5475448168355417, 0.5455962587685113, 0.5483242400623538, 0.5518316445830086, 0.5545596258768511, 0.5494933749025721, 0.5549493374902572, 0.5545596258768511, 0.5522213561964147, 0.5530007794232268, 0.5471551052221356, 0.5514419329696025, 0.5592361652377241, 0.5619641465315667, 0.5643024162120032, 0.5670303975058457, 0.5627435697583788, 0.5604053000779423, 0.5740452065471551, 0.5798908807482464, 0.5713172252533125, 0.568978955572876, 0.5701480904130943, 0.5705378020265004, 0.5771628994544037, 0.5806703039750585, 0.5826188620420889, 0.5810600155884645, 0.5798908807482464, 0.5841777084957132, 0.5837879968823071, 0.5923616523772408, 0.6013250194855807, 0.5950896336710834, 0.5950896336710834, 0.5915822291504287, 0.583008573655495, 0.5884645362431801, 0.5954793452844894, 0.5892439594699922, 0.593141075604053, 0.5915822291504287, 0.5896336710833983, 0.5985970381917382, 0.6009353078721746, 0.602883865939205, 0.5989867498051442, 0.5958690568978956, 0.5927513639906469, 0.5982073265783321, 0.6048324240062354, 0.6075604053000779, 0.6134060795011691, 0.6215900233826968, 0.6215900233826968, 0.6282151208106002, 0.6356196414653157, 0.6297739672642245, 0.6332813717848792, 0.6379579111457522, 0.6387373343725643, 0.6379579111457522, 0.6387373343725643, 0.6348402182385036, 0.6325019485580671, 0.6262665627435697, 0.6204208885424786, 0.6208106001558846, 0.607950116913484, 0.6071706936866719, 0.6056118472330475, 0.5982073265783321, 0.5985970381917382, 0.6005455962587685, 0.5997661730319563, 0.6017147310989868, 0.6063912704598597, 0.603273577552611, 0.6052221356196414, 0.6056118472330475, 0.6114575214341388, 0.6169134840218239, 0.6134060795011691, 0.6110678098207326, 0.6149649259547935, 0.6184723304754481, 0.6169134840218239, 0.6153546375681995, 0.6091192517537023, 0.6091192517537023, 0.6114575214341388, 0.6118472330475448, 0.6091192517537023, 0.6036632891660172, 0.5950896336710834, 0.588074824629774, 0.5954793452844894, 0.5923616523772408, 0.583398285268901, 0.5802805923616524, 0.5728760717069369, 0.56858924395947, 0.5623538581449727, 0.5631332813717849, 0.5643024162120032, 0.5604053000779423, 0.5557287607170693, 0.5498830865159782, 0.5510522213561965, 0.5510522213561965, 0.5494933749025721, 0.5506625097427903, 0.5479345284489477, 0.5409197194076384, 0.539360872954014, 0.5381917381137958, 0.5374123148869836, 0.5397505845674201, 0.5401402961808262, 0.5374123148869836, 0.5350740452065471, 0.5327357755261107, 0.5323460639127046, 0.539360872954014, 0.5370226032735775, 0.5335151987529229, 0.5370226032735775, 0.5370226032735775, 0.5339049103663289, 0.5311769290724864, 0.5327357755261107, 0.5362431800467654, 0.5405300077942322, 0.5374123148869836, 0.5339049103663289, 0.5331254871395168, 0.5335151987529229, 0.5339049103663289, 0.5350740452065471, 0.544037412314887, 0.5374123148869836, 0.5354637568199533, 0.5385814497272019, 0.534684333593141, 0.5381917381137958, 0.5315666406858924, 0.5307872174590803, 0.5366328916601715, 0.5381917381137958, 0.5409197194076384, 0.5366328916601715, 0.5374123148869836, 0.539360872954014, 0.5405300077942322, 0.5416991426344505, 0.539360872954014, 0.5432579890880749, 0.5436477007014809, 0.5420888542478566, 0.5381917381137958, 0.5444271239282931, 0.5444271239282931, 0.539360872954014, 0.5432579890880749, 0.5374123148869836, 0.5339049103663289, 0.5288386593920499, 0.5206547155105222, 0.5163678877630553, 0.5222135619641465, 0.5214341387373344, 0.5187061574434918, 0.5183164458300857, 0.5140296180826188, 0.5124707716289946, 0.5042868277474669, 0.49805144193296963, 0.4961028838659392, 0.49415432579890883, 0.48947778643803586, 0.485190958690569, 0.48791893998441155, 0.49025720966484804, 0.4929851909586906, 0.5, 0.4992205767731878, 0.5015588464536244, 0.5007794232268121, 0.49961028838659394, 0.5007794232268121, 0.4984411535463757, 0.5187061574434918, 0.5385814497272019, 0.5584567420109119, 0.5849571317225253, 0.6048324240062354, 0.6235385814497272, 0.642634450506625, 0.6640685892439595, 0.6819953234606392, 0.7084957131722526, 0.730709275136399, 0.7416212003117693, 0.754871395167576, 0.774746687451286, 0.7957911145752143, 0.8148869836321122, 0.8328137178487919, 0.8254091971940763, 0.7883865939204988, 0.7529228371005456, 0.7279812938425565, 0.7174590802805924, 0.7186282151208107, 0.7225253312548714, 0.7346063912704599, 0.7474668745128605, 0.7575993764614185, 0.765003897116134, 0.769290724863601, 0.7564302416212003, 0.7357755261106781, 0.7155105222135619, 0.6921278254091972, 0.6562743569758379, 0.6095089633671084, 0.5763834762275916, 0.5506625097427903, 0.5292283710054559, 0.5089633671083398, 0.4898674980514419, 0.4898674980514419, 0.4984411535463757, 0.5, 0.5058456742010912, 0.5140296180826188, 0.5276695245518317, 0.539360872954014, 0.5370226032735775, 0.538971161340608, 0.5459859703819174, 0.5502727981293842, 0.5533904910366328, 0.5471551052221356, 0.5452065471551052, 0.549103663289166, 0.5416991426344505, 0.5397505845674201, 0.5405300077942322, 0.538971161340608, 0.539360872954014, 0.5416991426344505, 0.5401402961808262, 0.5374123148869836, 0.539360872954014, 0.5416991426344505, 0.5416991426344505, 0.5413094310210445, 0.5409197194076384, 0.5416991426344505, 0.5350740452065471, 0.5362431800467654, 0.5444271239282931, 0.534294621979735, 0.5378020265003897, 0.5432579890880749, 0.5370226032735775, 0.5358534684333593, 0.5401402961808262, 0.5424785658612626, 0.5416991426344505, 0.5444271239282931, 0.5459859703819174, 0.5448168355416991, 0.5401402961808262, 0.5420888542478566, 0.5409197194076384, 0.538971161340608, 0.5459859703819174, 0.5471551052221356, 0.5452065471551052, 0.5452065471551052, 0.5428682774746687, 0.539360872954014, 0.539360872954014, 0.5416991426344505, 0.5424785658612626, 0.5467653936087296, 0.5459859703819174, 0.5424785658612626, 0.538971161340608, 0.5354637568199533, 0.5397505845674201, 0.5374123148869836, 0.5358534684333593, 0.5378020265003897, 0.5432579890880749, 0.5444271239282931, 0.5444271239282931, 0.5471551052221356, 0.5448168355416991, 0.5420888542478566, 0.5420888542478566, 0.5463756819953235, 0.54871395167576, 0.5514419329696025, 0.54871395167576, 0.5452065471551052, 0.5471551052221356, 0.5459859703819174, 0.5397505845674201, 0.5432579890880749, 0.549103663289166, 0.5444271239282931, 0.5475448168355417, 0.5459859703819174, 0.5420888542478566, 0.5475448168355417, 0.54871395167576, 0.544037412314887, 0.5479345284489477, 0.5526110678098207, 0.5518316445830086, 0.5530007794232268, 0.5565081839438816, 0.5475448168355417, 0.539360872954014, 0.544037412314887, 0.5479345284489477, 0.5483242400623538, 0.5459859703819174, 0.5502727981293842, 0.5498830865159782, 0.5514419329696025, 0.5459859703819174, 0.539360872954014, 0.5424785658612626, 0.5366328916601715, 0.5381917381137958, 0.538971161340608, 0.5374123148869836, 0.539360872954014, 0.5416991426344505, 0.5405300077942322, 0.5409197194076384, 0.5455962587685113, 0.5475448168355417, 0.5510522213561965, 0.5444271239282931, 0.5416991426344505, 0.5455962587685113, 0.544037412314887, 0.544037412314887, 0.5448168355416991, 0.5416991426344505, 0.5420888542478566, 0.5448168355416991, 0.5432579890880749, 0.54871395167576, 0.5463756819953235, 0.5444271239282931, 0.5475448168355417, 0.5479345284489477, 0.549103663289166, 0.5483242400623538, 0.5467653936087296, 0.5479345284489477, 0.549103663289166, 0.5409197194076384, 0.5463756819953235, 0.5420888542478566, 0.5378020265003897, 0.5436477007014809, 0.544037412314887, 0.5432579890880749, 0.5358534684333593, 0.5401402961808262, 0.5350740452065471, 0.5303975058456742, 0.5397505845674201, 0.5471551052221356, 0.54871395167576, 0.5405300077942322, 0.5370226032735775, 0.5428682774746687, 0.5452065471551052, 0.5413094310210445, 0.5381917381137958, 0.5405300077942322, 0.5420888542478566, 0.538971161340608, 0.5385814497272019, 0.5405300077942322, 0.5424785658612626, 0.5413094310210445, 0.5409197194076384, 0.5358534684333593, 0.5335151987529229, 0.5381917381137958, 0.539360872954014, 0.5397505845674201, 0.5350740452065471, 0.5358534684333593, 0.5362431800467654, 0.534684333593141, 0.5358534684333593, 0.5331254871395168, 0.5315666406858924, 0.534294621979735, 0.5401402961808262, 0.5362431800467654, 0.5272798129384255, 0.5331254871395168, 0.5335151987529229, 0.5311769290724864, 0.5405300077942322, 0.534684333593141, 0.5292283710054559, 0.5303975058456742, 0.5226032735775527, 0.5249415432579891, 0.5268901013250195, 0.5272798129384255, 0.5280592361652378, 0.5210444271239283, 0.5229929851909587, 0.524551831644583, 0.5261106780982073, 0.5268901013250195, 0.5241621200311769, 0.5241621200311769, 0.5226032735775527, 0.5210444271239283, 0.5226032735775527, 0.5229929851909587, 0.5237724084177708, 0.5276695245518317, 0.5280592361652378, 0.5226032735775527, 0.5151987529228371, 0.5175370226032736, 0.5288386593920499, 0.5303975058456742, 0.5226032735775527, 0.5202650038971162, 0.5265003897116134, 0.5222135619641465, 0.5190958690568979, 0.5249415432579891, 0.5218238503507404, 0.5179267342166797, 0.5163678877630553, 0.514419329696025, 0.514419329696025, 0.5167575993764614, 0.5206547155105222, 0.5222135619641465, 0.5210444271239283, 0.5222135619641465, 0.5194855806703039, 0.5113016367887763, 0.514419329696025, 0.5132501948558067, 0.5116913484021823, 0.5124707716289946, 0.5171473109898675, 0.524551831644583, 0.5249415432579891, 0.5265003897116134, 0.5229929851909587, 0.5222135619641465, 0.5226032735775527, 0.5261106780982073, 0.5272798129384255, 0.5261106780982073, 0.5303975058456742, 0.5261106780982073, 0.5280592361652378, 0.5311769290724864, 0.5323460639127046, 0.5315666406858924, 0.5327357755261107, 0.534294621979735, 0.5315666406858924, 0.5358534684333593, 0.5370226032735775, 0.5381917381137958, 0.5354637568199533, 0.534294621979735, 0.5374123148869836, 0.5381917381137958, 0.5378020265003897, 0.5374123148869836, 0.5432579890880749, 0.5381917381137958, 0.534684333593141, 0.539360872954014, 0.5370226032735775, 0.534294621979735, 0.5358534684333593, 0.539360872954014, 0.5444271239282931, 0.5444271239282931, 0.5416991426344505, 0.5401402961808262, 0.5416991426344505, 0.5424785658612626, 0.5428682774746687, 0.5463756819953235, 0.5452065471551052, 0.5405300077942322, 0.5366328916601715, 0.5374123148869836, 0.5354637568199533, 0.5378020265003897, 0.5401402961808262, 0.5409197194076384, 0.5455962587685113, 0.5467653936087296, 0.5452065471551052, 0.5413094310210445, 0.5420888542478566, 0.5416991426344505, 0.5374123148869836, 0.538971161340608, 0.5405300077942322, 0.5452065471551052, 0.5463756819953235, 0.5448168355416991, 0.5467653936087296, 0.5463756819953235, 0.5479345284489477, 0.5514419329696025, 0.5483242400623538, 0.5397505845674201, 0.5413094310210445, 0.5416991426344505, 0.5420888542478566, 0.5416991426344505, 0.5370226032735775, 0.539360872954014, 0.539360872954014, 0.5378020265003897, 0.5381917381137958, 0.5428682774746687, 0.544037412314887, 0.5424785658612626, 0.5401402961808262, 0.5354637568199533, 0.5378020265003897, 0.5409197194076384, 0.5428682774746687, 0.5424785658612626, 0.5436477007014809, 0.5479345284489477, 0.5448168355416991, 0.5471551052221356, 0.5530007794232268, 0.5510522213561965, 0.5514419329696025, 0.5506625097427903, 0.5385814497272019, 0.5366328916601715, 0.539360872954014, 0.5381917381137958, 0.5479345284489477, 0.5432579890880749, 0.539360872954014, 0.5432579890880749, 0.539360872954014, 0.5413094310210445, 0.544037412314887, 0.544037412314887, 0.5420888542478566, 0.5370226032735775, 0.539360872954014, 0.544037412314887, 0.5455962587685113, 0.5452065471551052, 0.5420888542478566, 0.5436477007014809, 0.5424785658612626, 0.5459859703819174, 0.5510522213561965, 0.54871395167576, 0.5428682774746687, 0.5405300077942322, 0.5452065471551052, 0.5428682774746687, 0.5452065471551052, 0.5428682774746687, 0.5405300077942322, 0.5428682774746687, 0.5413094310210445, 0.5510522213561965, 0.549103663289166, 0.5405300077942322, 0.5420888542478566, 0.5452065471551052, 0.5459859703819174, 0.5397505845674201, 0.5370226032735775, 0.5385814497272019, 0.5381917381137958, 0.5436477007014809, 0.5522213561964147, 0.5483242400623538, 0.5424785658612626, 0.5374123148869836, 0.5370226032735775, 0.5413094310210445, 0.5416991426344505, 0.5448168355416991, 0.5428682774746687, 0.5416991426344505, 0.5413094310210445, 0.5405300077942322, 0.544037412314887, 0.5424785658612626, 0.538971161340608, 0.5366328916601715, 0.5397505845674201, 0.5420888542478566, 0.5428682774746687, 0.5455962587685113, 0.5397505845674201, 0.5471551052221356, 0.5533904910366328, 0.5416991426344505, 0.5420888542478566, 0.5455962587685113, 0.5420888542478566, 0.539360872954014, 0.5409197194076384, 0.5432579890880749, 0.5448168355416991, 0.5448168355416991, 0.5428682774746687, 0.544037412314887, 0.5409197194076384, 0.5385814497272019, 0.5420888542478566, 0.5424785658612626, 0.5463756819953235, 0.544037412314887, 0.5385814497272019, 0.539360872954014, 0.5405300077942322, 0.5409197194076384, 0.5362431800467654, 0.5370226032735775, 0.534294621979735, 0.5315666406858924, 0.5350740452065471, 0.5378020265003897, 0.539360872954014, 0.5413094310210445, 0.5432579890880749, 0.5401402961808262, 0.5397505845674201, 0.5405300077942322, 0.5413094310210445, 0.5424785658612626, 0.5424785658612626, 0.538971161340608, 0.5378020265003897, 0.5374123148869836, 0.5401402961808262, 0.5455962587685113, 0.5409197194076384, 0.5424785658612626, 0.5420888542478566, 0.544037412314887, 0.5479345284489477, 0.5471551052221356, 0.5463756819953235, 0.5397505845674201, 0.538971161340608, 0.5331254871395168, 0.5354637568199533, 0.5413094310210445, 0.5420888542478566, 0.5459859703819174, 0.5459859703819174, 0.5428682774746687, 0.5448168355416991, 0.549103663289166, 0.5413094310210445, 0.5413094310210445, 0.5444271239282931, 0.5420888542478566, 0.5416991426344505, 0.5405300077942322, 0.539360872954014, 0.5385814497272019, 0.5416991426344505, 0.5436477007014809, 0.5432579890880749, 0.5432579890880749, 0.5428682774746687, 0.5444271239282931, 0.5428682774746687, 0.5405300077942322, 0.544037412314887, 0.5444271239282931, 0.5452065471551052, 0.5432579890880749, 0.5452065471551052, 0.549103663289166, 0.5420888542478566, 0.5436477007014809, 0.544037412314887, 0.5416991426344505, 0.5420888542478566, 0.5463756819953235, 0.5471551052221356, 0.5436477007014809, 0.5448168355416991, 0.5467653936087296, 0.5502727981293842, 0.544037412314887, 0.5413094310210445, 0.5416991426344505, 0.5413094310210445, 0.5467653936087296, 0.5483242400623538, 0.5428682774746687, 0.5413094310210445, 0.5416991426344505, 0.534294621979735, 0.534294621979735, 0.534294621979735, 0.5307872174590803, 0.5401402961808262, 0.5405300077942322, 0.534684333593141, 0.5385814497272019, 0.5405300077942322, 0.5444271239282931, 0.5436477007014809, 0.5444271239282931, 0.5432579890880749, 0.5366328916601715, 0.5366328916601715, 0.534294621979735, 0.5350740452065471, 0.534684333593141, 0.5350740452065471, 0.5370226032735775, 0.5401402961808262, 0.5420888542478566, 0.5436477007014809, 0.5436477007014809, 0.5397505845674201, 0.5416991426344505, 0.5405300077942322, 0.5405300077942322, 0.5405300077942322, 0.5428682774746687, 0.5424785658612626, 0.5378020265003897]



predicted_points = iterative_forecast(initial_points, model, steps=10)

# Plotting
plt.figure(figsize=(12, 6))
plt.plot(range(1600), initial_points, label='Initial Data')
plt.plot(range(1600, 2600), predicted_points[1600:], label='Predicted Data')
plt.title("ECG Signal Forecasting")
plt.xlabel("Time Steps")
plt.ylabel("ECG Signal Value")
plt.legend()
plt.show()